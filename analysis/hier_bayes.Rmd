---
title: "hier_bayes"
output: html_document
---

```{r include=F}
library(extraDistr)
library(distr)
library(ggplot2)
library(rstan)
suppressPackageStartupMessages(require(ggplot2))
suppressPackageStartupMessages(require(dplyr))
suppressPackageStartupMessages(require(bayesplot))
suppressPackageStartupMessages(require(tidybayes))
library(AmesHousing)

```

Data
```{r}
ames_df2 = make_ordinal_ames()
vars <- c("Sale_Price", "Lot_Area", "Gr_Liv_Area", "Year_Built", "Full_Bath", "Neighborhood")
ames_small <- ames_df2[, vars]
ames_small <- na.omit(ames_small)
```

```{r}
ames_small |> group_by(Neighborhood) |>
  summarise(count = n(),
            avg_sale_price = mean(Sale_Price)) |>
  mutate(percent = count / sum(count) * 100)
```

```{r}

ames_small$neigh_id <- as.integer(factor(ames_small$Neighborhood))

ames_small <- ames_small %>%
  mutate(Sale_Price = log(Sale_Price))

G <- length(unique(ames_small$neigh_id))

X <- model.matrix(Sale_Price ~ . - Neighborhood - 1, data = ames_small)
X <- scale(X)

y <- ames_small$Sale_Price
x_pred <- X[1, ]

data_list <- list(
  N = nrow(X),
  K = ncol(X),
  X = X,
  y = y,
  G = G,
  gid = ames_small$neigh_id,
  x_pred = x_pred,
  group_pred = 1
)


fit <- stan(
  file = "hier_neigh_model.stan",
  data = data_list,
  iter = 1000,
  chains = 4,
  seed = 447
)

```

Posterior predictive

```{r}
y_rep <- rstan::extract(fit, "y_rep")$y_rep
ppc_dens_overlay(y = ames_small$Sale_Price, yrep = y_rep[1:100, ])

```


```{r}
posterior_y <- extract(fit)$y_pred
hist(posterior_y, main = "Posterior Predictive Distribution", xlab = "Predicted y")
abline(v = mean(posterior_y), col = "red")

```


LOO callibration

```{r}

hier_model = stan_model("hier_neigh_model.stan")


ames_small$neigh_id <- as.integer(factor(ames_small$Neighborhood))
G <- length(unique(ames_small$neigh_id))
y <- ames_small$Sale_Price
x_pred <- X[1, ]


N_obs = nrow(X)

set.seed(447)
loo_indices <- sample(1:nrow(ames_small), size = 50)

ci_limits = matrix(0, nrow=length(loo_indices), 2)
ci_level = 0.8
ci_plims = c((1-ci_level)/2, (1+ci_level)/2) 

for(i_test in 1:50) {
   train_test_data= list(
     N = N_obs - 1,
     K = ncol(X),
     X = X[-i_test, ],
     y = y[-i_test],
     G = G,
     gid = (ames_small$neigh_id)[-i_test],
     x_pred = X[i_test,],
     group_pred = (ames_small$neigh_id)[i_test]
   )
   
   mcmc_res = sampling(
    object = hier_model,
    data = train_test_data,
    iter = 500,
    chains = 1
    )
   
   samples= extract(mcmc_res)
   ci_limits[i_test,]= quantile(samples$y_pred,ci_plims)
}
```




```{r}

df = data.frame(
  y = y[1:50]
)

ci_limits = ci_limits[1:50, ]

 merged_df = df %>%
 bind_cols(data.frame(CI_L = ci_limits[,1], CI_R = ci_limits[,2])) %>%
 mutate(Inside_CI = (y >= CI_L & y <= CI_R))
 merged_df %>%
 ggplot(aes(x = 1:50, y = y, ymin = CI_L, ymax = CI_R, color=Inside_CI)) +
 geom_point() +
 geom_errorbar() +
 theme_minimal() +
 labs(x = "Point", y = "Prediction")

```
MCMC diagnostics
Summary
```{r}
summary(fit)$summary
```



Trace plot
```{r}
traceplot(fit)
```

```{r}
mcmc_trace(fit) + theme_minimal()

```
Rank plot

```{r}
mcmc_rank_hist(fit) + theme_minimal()

```

Synthetic data (not complete)
```{r}
set.seed(123)
N_sim <- 200
G_sim <- 5
x_sim <- rnorm(N_sim)
group_sim <- sample(1:G_sim, N_sim, replace = TRUE)
alpha_true <- rnorm(G_sim, 10, 1)
beta_true <- 2.5
y_sim <- alpha_true[group_sim] + beta_true * x_sim + rnorm(N_sim, 0, 1)



data_list <- list(
  N = N_sim,
  K = 1,
  X = x_sim,
  y = y_sim,
  G = G_sim,
  gid = group_sim,
  x_pred = x_sim[1],
  group_pred = 1
)


fit_syn <- stan(
  file = "hier_neigh_model.stan",
  data = data_list,
  iter = 1000,
  chains = 4,
  seed = 447
)

```



